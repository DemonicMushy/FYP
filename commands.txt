python train.py --scenario simple_tag --num-adversaries 3 --num-episodes 10000 --save-dir "./policy-simple_tag-discrete-60000/" --exp-name simple_tag --benchmark
python train.py --scenario tag_adv_comm_and_direction --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_adv_comm_and_direction-c4-60000/" --exp-name tag_adv_comm_and_direction_c4 --benchmark

python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base-60000/" --exp-name tag_scenario_base --benchmark
python train.py --scenario tag_scenario1 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario1-60000/" --exp-name tag_scenario1 --benchmark
python train.py --scenario tag_scenario1 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario1-120000/" --exp-name tag_scenario1_120000 --benchmark
python train.py --scenario tag_scenario1 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario1_fix_2-60000/" --exp-name tag_scenario1_fix_2 --benchmark

python train.py --scenario tag_scenario2 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario2-60000/" --exp-name tag_scenario2 --benchmark
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_2-60000/" --exp-name tag_scenario_base_2 --benchmark
python train.py --scenario tag_scenario3 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario3-60000/" --exp-name tag_scenario3 --benchmark
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 10000 --save-dir "./policy-tag_scenario_base_2-10000/" --exp-name tag_scenario_base_2-10000 --benchmark
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 20000 --save-dir "./policy-tag_scenario_base_2-20000/" --exp-name tag_scenario_base_2-20000 --benchmark
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 30000 --save-dir "./policy-tag_scenario_base_2-30000/" --exp-name tag_scenario_base_2-30000 --benchmark
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 40000 --save-dir "./policy-tag_scenario_base_2-40000/" --exp-name tag_scenario_base_2-40000 --benchmark
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 50000 --save-dir "./policy-tag_scenario_base_2-50000/" --exp-name tag_scenario_base_2-50000 --benchmark
python train.py --scenario tag_scenario4 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario4-60000/" --exp-name tag_scenario4 --benchmark
python train.py --scenario tag_scenario3 --num-adversaries 3 --num-episodes 10000 --save-dir "./policy-tag_scenario3-10000/" --exp-name tag_scenario3-10000 --benchmark

python train.py --scenario tag_scenario3 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario3_fix-60000/" --exp-name tag_scenario3_fix --benchmark
python train.py --scenario tag_scenario3 --num-adversaries 3 --num-episodes 10000 --save-dir "./policy-tag_scenario3_fix-10000/" --exp-name tag_scenario3_fix-10000 --benchmark
python train.py --scenario tag_scenario3 --num-adversaries 3 --num-episodes 1000 --save-dir "./policy-tag_scenario3_fix-1000/" --exp-name tag_scenario3_fix-1000 

python train.py --scenario tag_scenario_base_wDistance --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_wdistance-60000/" --exp-name tag_scenario_base_wDistance --benchmark
python train.py --scenario tag_scenario_base_wDistanceAll --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_wdistanceAll-60000/" --exp-name tag_scenario_base_wDistanceAll --benchmark
python train.py --scenario tag_scenario3_woDirection --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario3_woDirection-60000/" --exp-name tag_scenario3_woDirection --benchmark

python train.py --scenario tag_scenario3 --num-adversaries 3 --save-dir "./z_test/" --load-dir "./z_test/" --exp-name z_test --display

python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_2-60000/" --exp-name fixedGA_tag_scenario_base_2 --use-same-good-agent --benchmark
python train.py --scenario tag_scenario2 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario2-60000/" --exp-name fixedGA_tag_scenario2 --use-same-good-agent --benchmark
python train.py --scenario tag_scenario3 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario3_fix-60000/" --exp-name fixedGA_tag_scenario3 --use-same-good-agent --benchmark
python train.py --scenario tag_scenario4 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario4-60000/" --exp-name fixedGA_tag_scenario4 --use-same-good-agent --benchmark
python train.py --scenario tag_scenario_base_wDistance --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_wdistance-60000/" --exp-name fixedGA_tag_scenario_base_wDistance --use-same-good-agent --benchmark
python train.py --scenario tag_scenario_base_wDistanceAll --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_wdistanceAll-60000/" --exp-name fixedGA_tag_scenario_base_wDistanceAll --use-same-good-agent --benchmark
python train.py --scenario tag_scenario3_woDirection --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario3_woDirection-60000/" --exp-name fixedGA_tag_scenario3_woDirection --use-same-good-agent --benchmark

python train.py --scenario tag_scenario5 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario5-60000/" --exp-name tag_scenario5 --benchmark
python train.py --scenario tag_scenario5 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario5-60000/" --exp-name fixedGA_tag_scenario5 --use-same-good-agent --benchmark
python train.py --scenario tag_scenario_base2 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base2-60000/" --exp-name tag_scenario_base2 --benchmark
python train.py --scenario tag_scenario_base2 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base2-60000/" --exp-name fixedGA_tag_scenario_base2 --use-same-good-agent --benchmark
# end of 17th Dec

# run this
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_2-60000/" --exp-name tag_scenario_base_2 --benchmark &&
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_2-60000/" --exp-name fixedGA_tag_scenario_base_2 --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario2 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario2-60000/" --exp-name fixedGA_tag_scenario2 --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario3 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario3_fix-60000/" --exp-name fixedGA_tag_scenario3 --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario4 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario4-60000/" --exp-name fixedGA_tag_scenario4 --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario_base_wDistance --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_wdistance-60000/" --exp-name fixedGA_tag_scenario_base_wDistance --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario_base_wDistanceAll --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_wdistanceAll-60000/" --exp-name fixedGA_tag_scenario_base_wDistanceAll --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario3_woDirection --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario3_woDirection-60000/" --exp-name fixedGA_tag_scenario3_woDirection --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario5 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario5-60000/" --exp-name fixedGA_tag_scenario5 --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario_base2 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base2-60000/" --exp-name fixedGA_tag_scenario_base2 --use-same-good-agent --benchmark

python train.py --scenario tag_s_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s_base-60000/" --exp-name tag_s_base --benchmark
python train.py --scenario tag_s_base_Wdistance --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s_base_Wdistance-60000/" --exp-name tag_s_base_Wdistance --benchmark
python train.py --scenario tag_s_comm --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s_comm-60000/" --exp-name tag_s_comm --benchmark

python train.py --scenario tag_s1_base --num-adversaries 3 --max-episode-len 125 --num-episodes 60000 --save-dir "./policy-tag_s1_base-60000/" --exp-name tag_s1_base --benchmark

python train.py --scenario tag_s_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s_base_run2-60000/" --exp-name tag_s_base_run2 --benchmark
python train.py --scenario tag_s_base_Wdistance --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s_base_Wdistance_run2-60000/" --exp-name tag_s_base_Wdistance_run2 --benchmark
python train.py --scenario tag_s_comm --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s_comm_run2-60000/" --exp-name tag_s_comm_run2 --benchmark

python train.py --scenario tag_s0_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s0_base-60000/" --exp-name tag_s0_base --benchmark
python train.py --scenario tag_s0_base_Wdistance --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s0_base_Wdistance-60000/" --exp-name tag_s0_base_Wdistance --benchmark
python train.py --scenario tag_s0_comm --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s0_comm-60000/" --exp-name tag_s0_comm --benchmark

python train.py --scenario tag_s0_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s0_base_run2-60000/" --exp-name tag_s0_base_run2 --benchmark
python train.py --scenario tag_s0_base_Wdistance --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s0_base_Wdistance_run2-60000/" --exp-name tag_s0_base_Wdistance_run2 --benchmark
python train.py --scenario tag_s0_comm --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s0_comm_run2-60000/" --exp-name tag_s0_comm_run2 --benchmark

python train.py --scenario tag_s_comm --num-adversaries 3 --num-episodes 30000 --load-dir "./policy-tag_s_comm-60000/" --save-dir "./policy-tag_s_comm-90000/" --exp-name tag_s_comm_9000 --benchmark

python runExperiments.py --scenario tag_s_los_comm --start-iter 1 --end-iter 6 --num-units 64 --initial-exp-name tag_s_los_comm_LONG --initial-dir "./policy-tag_s_los_comm_LONG"


python runExperiments.py --scenario tag_s_base --start-iter 1 --end-iter 12 --num-units-adv 32 --num-units-good 64 --initial-exp-name tag_s_base_32_64_LONG --initial-dir "./policy-tag_s_base_32_64_LONG"
python runExperiments.py --scenario tag_s_base_Wdistance --start-iter 1 --end-iter 12 --num-units-adv 32 --num-units-good 64 --initial-exp-name tag_s_base_Wdistance_32_64_LONG --initial-dir "./policy-tag_s_base_Wdistance_32_64_LONG"
python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 12 --num-units-adv 32 --num-units-good 64 --initial-exp-name tag_s_comm_32_64_LONG --initial-dir "./policy-tag_s_comm_32_64_LONG"

python runExperiments.py --scenario tag_s_base --start-iter 1 --end-iter 6 --initial-exp-name tag_s_base__64_32__LONG --initial-dir "./policy-tag_s_base__64_32__LONG" --benchmark-interval 2
python runExperiments.py --scenario tag_s_base_Wdistance --start-iter 1 --end-iter 6 --initial-exp-name tag_s_base_Wdistance__64_32__LONG --initial-dir "./policy-tag_s_base_Wdistance__64_32__LONG" --benchmark-interval 2
python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --initial-exp-name tag_s_comm__64_32__LONG --initial-dir "./policy-tag_s_comm__64_32__LONG" --benchmark-interval 2


python runExperiments.py --scenario tag_s_base --start-iter 1 --end-iter 6 --num-units-adv 32 --initial-exp-name tag_s_base__32__LONG --initial-dir "./policy-tag_s_base__32__LONG" --benchmark-interval 2
python runExperiments.py --scenario tag_s_base_Wdistance --start-iter 1 --end-iter 6 --num-units-adv 32 --initial-exp-name tag_s_base_Wdistance__32__LONG --initial-dir "./policy-tag_s_base_Wdistance__32__LONG" --benchmark-interval 2
python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --num-units-adv 32 --initial-exp-name tag_s_comm__32__LONG --initial-dir "./policy-tag_s_comm__32__LONG" --benchmark-interval 2

python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --num-units-adv 16 --initial-exp-name tag_s_comm__16__LONG --initial-dir "./policy-tag_s_comm__16__LONG" --benchmark-interval 2
python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --num-units-adv 128 --initial-exp-name tag_s_comm__128__LONG --initial-dir "./policy-tag_s_comm__128__LONG" --benchmark-interval 2


python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --initial-exp-name tag_s_comm__64_64_64__LONG --initial-dir "./policy-tag_s_comm__64_64_64__LONG" --benchmark-interval 2
python runExperiments2.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --initial-exp-name tag_s_comm__64_32_64__LONG --initial-dir "./policy-tag_s_comm__64_32_64__LONG" --benchmark-interval 2
python runExperiments3.py --scenario tag_s_base_Wdistance --start-iter 16 --end-iter 18 --initial-exp-name tag_s_base_Wdistance_LONG --initial-dir "./policy-tag_s_base_Wdistance_LONG" --benchmark-interval 1

python runExperiments3.py --scenario tag_s_comm --start-iter 16 --end-iter 18 --initial-exp-name tag_s_comm_LONG --initial-dir "./policy-tag_s_comm_LONG" --benchmark-interval 1
python runExperiments3.py --scenario tag_s_base --start-iter 16 --end-iter 18 --initial-exp-name tag_s_base_LONG --initial-dir "./policy-tag_s_base_LONG" --benchmark-interval 1


python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --initial-exp-name tag_s_comm__64_32__LONG2 --initial-dir "./policy-tag_s_comm__64_32__LONG2" --benchmark-interval 2
python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --initial-exp-name tag_s_comm__64_32__LONG3 --initial-dir "./policy-tag_s_comm__64_32__LONG3" --benchmark-interval 2


python runExperiments.py --scenario tag_s_comm --start-iter 7 --end-iter 8 --initial-exp-name tag_s_comm__64_32__LONG --initial-dir "./policy-tag_s_comm__64_32__LONG" --benchmark-interval 2 &&
python runExperiments.py --scenario tag_s_comm --start-iter 7 --end-iter 8 --initial-exp-name tag_s_comm__64_32__LONG2 --initial-dir "./policy-tag_s_comm__64_32__LONG2" --benchmark-interval 2 &&
python runExperiments.py --scenario tag_s_comm --start-iter 7 --end-iter 8 --initial-exp-name tag_s_comm__64_32__LONG3 --initial-dir "./policy-tag_s_comm__64_32__LONG3" --benchmark-interval 2 &&
shutdown now


python train3.py --num-adversaries 3 --num-episodes 10000 --scenario tag_s_comm --save-dir ./policy-tag_s_comm_LONG_30000/ --exp-name tag_s_comm_LONG_30000 --display

python runExperiments3.py --scenario tag_s_comm --start-iter 1 --end-iter 20 --num-episodes 2000 --initial-exp-name tag_s_comm_SHORT --initial-dir "./policy-tag_s_comm_SHORT"
python runExperiments3.py --scenario tag_s_comm --start-iter 1 --end-iter 20 --num-episodes 2000 --initial-exp-name tag_s_comm_2SHORT --initial-dir "./policy-tag_s_comm_2SHORT" --benchmark no


python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --initial-exp-name tag_s_comm__64_96_64_32__LONG --initial-dir "./policy-tag_s_comm__64_96_64_32__LONG"

python runExperiments2.py --scenario tag_s_comm --start-iter 7 --end-iter 10 --initial-exp-name tag_s_comm__128_64_32__LONG --initial-dir "./policy-tag_s_comm__128_64_32__LONG" &&
python runExperiments2.py --scenario tag_s_comm --start-iter 1 --end-iter 10 --initial-exp-name tag_s_comm__128_64_32__2LONG --initial-dir "./policy-tag_s_comm__128_64_32__2LONG" &&
shutdown now


python runExperiments3.py --scenario tag_s_base --start-iter 1 --end-iter 20 --num-episodes 2000 --initial-exp-name tag_s_base_SHORT --initial-dir "./policy-tag_s_base_SHORT"
python runExperiments3.py --scenario tag_s_base_Wdistance --start-iter 1 --end-iter 20 --num-episodes 2000 --initial-exp-name tag_s_base_Wdistance_SHORT --initial-dir "./policy-tag_s_base_Wdistance_SHORT"

python runExperiments3.py --scenario tag_s_base_Wdistance --start-iter 8 --end-iter 20 --num-episodes 2000 --initial-exp-name tag_s_base_Wdistance_SHORT --initial-dir "./policy-tag_s_base_Wdistance_SHORT" &&
shutdown now

128 - 64 - 32 - 5
64 - 32 - 5
64 - 96 - 64 - 32 - 5

literature on how to design network around useful and unuseful information, (autoencoders)

python runMultipleExps.py --file runExperiments3.py --file-runs 5 --scenario tag_s_comm --start-iter 1 --end-iter 10 --num-episodes 2000 --initial-exp-name comm --initial-dir "./policy-comm" --benchmark-filecount 10

python runMultipleExps.py --file runExperiments3.py --file-runs 5 --scenario tag_s_comm --start-iter 1 --end-iter 20 --num-episodes 2000 --initial-exp-name comm --initial-dir "./policy-comm" --benchmark-filecount 10
python runMultipleExps.py --file runExperiments3.py --file-runs 5 --scenario tag_s_comm --start-iter 1 --end-iter 20 --num-episodes 2000 --initial-exp-name comm1 --initial-dir "./policy-comm1" --benchmark-filecount 10
python runMultipleExps.py --file runExperiments3.py --file-runs 5 --scenario tag_s_comm --start-iter 1 --end-iter 20 --num-episodes 2000 --initial-exp-name comm --initial-dir "./policy-comm2" --benchmark-filecount 10
python runMultipleExps.py --file runExperiments3.py --file-runs 5 --scenario tag_s_comm --start-iter 1 --end-iter 20 --num-episodes 2000 --initial-exp-name comm1 --initial-dir "./policy-comm3" --benchmark-filecount 10
// messed up the naming of exp-name for 3rd and 4th

python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_comm --start-iter 1 --end-iter 20 --num-episodes 2000 --initial-exp-name commSpecial_128_64_32 --initial-dir "./policy-commSpecial_128_64_32" --benchmark-filecount 1


python runMultipleExps.py --file runExperiments3.py --file-runs 5 --scenario tag_s_comm --start-iter 21 --end-iter 30 --num-episodes 2000 --initial-exp-name comm --initial-dir "./policy-comm" --benchmark-filecount 1
python runMultipleExps.py --file runExperiments3.py --file-runs 5 --scenario tag_s_comm --start-iter 21 --end-iter 30 --num-episodes 2000 --initial-exp-name comm1 --initial-dir "./policy-comm1" --benchmark-filecount 1
python runMultipleExps.py --file runExperiments3.py --file-runs 5 --scenario tag_s_comm --start-iter 21 --end-iter 30 --num-episodes 2000 --initial-exp-name comm2 --initial-dir "./policy-comm2" --benchmark-filecount 1


python runMultipleExps.py --file runExperiments3.py --file-runs 5 --scenario tag_s_comm --start-iter 21 --end-iter 30 --num-episodes 2000 --initial-exp-name comm3 --initial-dir "./policy-comm3" --benchmark-filecount 1 
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_comm --start-iter 21 --end-iter 30 --num-episodes 2000 --initial-exp-name commSpecial_128_64_32 --initial-dir "./policy-commSpecial_128_64_32" --benchmark-filecount 1 
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_base_Wdistance --start-iter 1 --end-iter 30 --num-episodes 2000 --initial-exp-name distSpecial_128_64_32 --initial-dir "./policy-distSpecial_128_64_32" --benchmark-filecount 1 


python runMultipleExps.py --file runExperiments3.py --file-runs 5 --scenario tag_s_base --start-iter 1 --end-iter 30 --num-episodes 2000 --initial-exp-name base_3 --initial-dir "./policy-tag_s_base_3" --benchmark-filecount 1

python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1 --start-iter 1 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1_128_64_32_0 --initial-dir "./policy-lying1_128_64_32_0" --benchmark no
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1 --start-iter 30 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1_128_64_32_0 --initial-dir "./policy-lying1_128_64_32_0" --benchmark only --benchmark-filecount 1

python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1 --start-iter 1 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1_128_64_32_1 --initial-dir "./policy-lying1_128_64_32_1" --benchmark no &&
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1 --start-iter 30 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1_128_64_32_1 --initial-dir "./policy-lying1_128_64_32_1" --benchmark only --benchmark-filecount 1

python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1 --start-iter 1 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1_128_64_32_2 --initial-dir "./policy-lying1_128_64_32_2" --benchmark no &&
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1 --start-iter 30 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1_128_64_32_2 --initial-dir "./policy-lying1_128_64_32_2" --benchmark only --benchmark-filecount 1

python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1 --start-iter 1 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1_128_64_32_3 --initial-dir "./policy-lying1_128_64_32_3" --benchmark no &&
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1 --start-iter 30 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1_128_64_32_3 --initial-dir "./policy-lying1_128_64_32_3" --benchmark only --benchmark-filecount 1

// to fix the missing policy files from previous mistake
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_comm --start-iter 1 --end-iter 30 --num-episodes 2000 --initial-exp-name commSpecial_128_64_32 --initial-dir "./policy-commSpecial_128_64_32" --benchmark no 

// the week discussed about variance reduction
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_comm --start-iter 31 --end-iter 50 --num-episodes 2000 --initial-exp-name commSpecial_128_64_32 --initial-dir "./policy-commSpecial_128_64_32" --benchmark-filecount 1 
python runMultipleExps.py --file runExperiments2.py --file-runs 4 --scenario tag_s_comm --start-iter 41 --end-iter 50 --num-episodes 2000 --initial-exp-name commSpecial_128_64_32_1 --initial-dir "./policy-commSpecial_128_64_32_1" --benchmark-filecount 1
python runMultipleExps.py --file runExperiments2.py --file-runs 4 --scenario tag_s_comm --start-iter 41 --end-iter 50 --num-episodes 2000 --initial-exp-name commSpecial_128_64_32_2 --initial-dir "./policy-commSpecial_128_64_32_2" --benchmark-filecount 1

// get 5 more for commSpecial_128_64_32 (13 -> 18) | sent to scsegpu to do
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_comm --start-iter 1 --end-iter 20 --num-episodes 2000 --initial-exp-name commSpecial_128_64_32_0 --initial-dir "./policy-commSpecial_128_64_32_0" --benchmark-filecount 1
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_comm --start-iter 31 --end-iter 50 --num-episodes 2000 --initial-exp-name commSpecial_128_64_32_0 --initial-dir "./policy-commSpecial_128_64_32_0" --benchmark-filecount 1 


// solo lying
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 1 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_0 --initial-dir "./policy-lying1single_128_64_32_0" --benchmark no &&
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 30 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_0 --initial-dir "./policy-lying1single_128_64_32_0" --benchmark only --benchmark-filecount 1
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 1 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_1 --initial-dir "./policy-lying1single_128_64_32_1" --benchmark no &&
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 30 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_1 --initial-dir "./policy-lying1single_128_64_32_1" --benchmark only --benchmark-filecount 1
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 1 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_2 --initial-dir "./policy-lying1single_128_64_32_2" --benchmark no &&
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 30 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_2 --initial-dir "./policy-lying1single_128_64_32_2" --benchmark only --benchmark-filecount 1
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 1 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_3 --initial-dir "./policy-lying1single_128_64_32_3" --benchmark no &&

python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 5 --end-iter 15 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_3 --initial-dir "./policy-lying1single_128_64_32_3" --benchmark only --benchmark-filecount 1
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 17 --end-iter 30 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_3 --initial-dir "./policy-lying1single_128_64_32_3" --benchmark only --benchmark-filecount 1
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 1 --end-iter 15 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_2 --initial-dir "./policy-lying1single_128_64_32_2" --benchmark only --benchmark-filecount 1
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 16 --end-iter 29 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_2 --initial-dir "./policy-lying1single_128_64_32_2" --benchmark only --benchmark-filecount 1

python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 1 --end-iter 10 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_1 --initial-dir "./policy-lying1single_128_64_32_1" --benchmark only --benchmark-filecount 1
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 11 --end-iter 20 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_1 --initial-dir "./policy-lying1single_128_64_32_1" --benchmark only --benchmark-filecount 1


python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 21 --end-iter 24 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_1 --initial-dir "./policy-lying1single_128_64_32_1" --benchmark only --benchmark-filecount 1
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 1 --end-iter 15 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_0 --initial-dir "./policy-lying1single_128_64_32_0" --benchmark only --benchmark-filecount 1
--
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 25 --end-iter 29 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_1 --initial-dir "./policy-lying1single_128_64_32_1" --benchmark only --benchmark-filecount 1
python runMultipleExps.py --file runExperiments2.py --file-runs 5 --scenario tag_s_lying1single --start-iter 16 --end-iter 29 --num-episodes 2000 --initial-exp-name lying1single_128_64_32_0 --initial-dir "./policy-lying1single_128_64_32_0" --benchmark only --benchmark-filecount 1


curl -X POST -d 'message=right done' 192.168.0.174:50500/notify