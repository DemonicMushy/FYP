python train.py --scenario simple_tag --num-adversaries 3 --num-episodes 10000 --save-dir "./policy-simple_tag-discrete-60000/" --exp-name simple_tag --benchmark
python train.py --scenario tag_adv_comm_and_direction --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_adv_comm_and_direction-c4-60000/" --exp-name tag_adv_comm_and_direction_c4 --benchmark

python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base-60000/" --exp-name tag_scenario_base --benchmark
python train.py --scenario tag_scenario1 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario1-60000/" --exp-name tag_scenario1 --benchmark
python train.py --scenario tag_scenario1 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario1-120000/" --exp-name tag_scenario1_120000 --benchmark
python train.py --scenario tag_scenario1 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario1_fix_2-60000/" --exp-name tag_scenario1_fix_2 --benchmark

python train.py --scenario tag_scenario2 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario2-60000/" --exp-name tag_scenario2 --benchmark
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_2-60000/" --exp-name tag_scenario_base_2 --benchmark
python train.py --scenario tag_scenario3 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario3-60000/" --exp-name tag_scenario3 --benchmark
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 10000 --save-dir "./policy-tag_scenario_base_2-10000/" --exp-name tag_scenario_base_2-10000 --benchmark
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 20000 --save-dir "./policy-tag_scenario_base_2-20000/" --exp-name tag_scenario_base_2-20000 --benchmark
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 30000 --save-dir "./policy-tag_scenario_base_2-30000/" --exp-name tag_scenario_base_2-30000 --benchmark
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 40000 --save-dir "./policy-tag_scenario_base_2-40000/" --exp-name tag_scenario_base_2-40000 --benchmark
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 50000 --save-dir "./policy-tag_scenario_base_2-50000/" --exp-name tag_scenario_base_2-50000 --benchmark
python train.py --scenario tag_scenario4 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario4-60000/" --exp-name tag_scenario4 --benchmark
python train.py --scenario tag_scenario3 --num-adversaries 3 --num-episodes 10000 --save-dir "./policy-tag_scenario3-10000/" --exp-name tag_scenario3-10000 --benchmark

python train.py --scenario tag_scenario3 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario3_fix-60000/" --exp-name tag_scenario3_fix --benchmark
python train.py --scenario tag_scenario3 --num-adversaries 3 --num-episodes 10000 --save-dir "./policy-tag_scenario3_fix-10000/" --exp-name tag_scenario3_fix-10000 --benchmark
python train.py --scenario tag_scenario3 --num-adversaries 3 --num-episodes 1000 --save-dir "./policy-tag_scenario3_fix-1000/" --exp-name tag_scenario3_fix-1000 

python train.py --scenario tag_scenario_base_wDistance --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_wdistance-60000/" --exp-name tag_scenario_base_wDistance --benchmark
python train.py --scenario tag_scenario_base_wDistanceAll --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_wdistanceAll-60000/" --exp-name tag_scenario_base_wDistanceAll --benchmark
python train.py --scenario tag_scenario3_woDirection --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario3_woDirection-60000/" --exp-name tag_scenario3_woDirection --benchmark

python train.py --scenario tag_scenario3 --num-adversaries 3 --save-dir "./z_test/" --load-dir "./z_test/" --exp-name z_test --display

python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_2-60000/" --exp-name fixedGA_tag_scenario_base_2 --use-same-good-agent --benchmark
python train.py --scenario tag_scenario2 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario2-60000/" --exp-name fixedGA_tag_scenario2 --use-same-good-agent --benchmark
python train.py --scenario tag_scenario3 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario3_fix-60000/" --exp-name fixedGA_tag_scenario3 --use-same-good-agent --benchmark
python train.py --scenario tag_scenario4 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario4-60000/" --exp-name fixedGA_tag_scenario4 --use-same-good-agent --benchmark
python train.py --scenario tag_scenario_base_wDistance --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_wdistance-60000/" --exp-name fixedGA_tag_scenario_base_wDistance --use-same-good-agent --benchmark
python train.py --scenario tag_scenario_base_wDistanceAll --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_wdistanceAll-60000/" --exp-name fixedGA_tag_scenario_base_wDistanceAll --use-same-good-agent --benchmark
python train.py --scenario tag_scenario3_woDirection --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario3_woDirection-60000/" --exp-name fixedGA_tag_scenario3_woDirection --use-same-good-agent --benchmark

python train.py --scenario tag_scenario5 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario5-60000/" --exp-name tag_scenario5 --benchmark
python train.py --scenario tag_scenario5 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario5-60000/" --exp-name fixedGA_tag_scenario5 --use-same-good-agent --benchmark
python train.py --scenario tag_scenario_base2 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base2-60000/" --exp-name tag_scenario_base2 --benchmark
python train.py --scenario tag_scenario_base2 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base2-60000/" --exp-name fixedGA_tag_scenario_base2 --use-same-good-agent --benchmark
# end of 17th Dec

# run this
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_2-60000/" --exp-name tag_scenario_base_2 --benchmark &&
python train.py --scenario tag_scenario_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_2-60000/" --exp-name fixedGA_tag_scenario_base_2 --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario2 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario2-60000/" --exp-name fixedGA_tag_scenario2 --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario3 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario3_fix-60000/" --exp-name fixedGA_tag_scenario3 --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario4 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario4-60000/" --exp-name fixedGA_tag_scenario4 --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario_base_wDistance --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_wdistance-60000/" --exp-name fixedGA_tag_scenario_base_wDistance --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario_base_wDistanceAll --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base_wdistanceAll-60000/" --exp-name fixedGA_tag_scenario_base_wDistanceAll --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario3_woDirection --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario3_woDirection-60000/" --exp-name fixedGA_tag_scenario3_woDirection --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario5 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario5-60000/" --exp-name fixedGA_tag_scenario5 --use-same-good-agent --benchmark &&
python train.py --scenario tag_scenario_base2 --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_scenario_base2-60000/" --exp-name fixedGA_tag_scenario_base2 --use-same-good-agent --benchmark

python train.py --scenario tag_s_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s_base-60000/" --exp-name tag_s_base --benchmark
python train.py --scenario tag_s_base_Wdistance --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s_base_Wdistance-60000/" --exp-name tag_s_base_Wdistance --benchmark
python train.py --scenario tag_s_comm --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s_comm-60000/" --exp-name tag_s_comm --benchmark

python train.py --scenario tag_s1_base --num-adversaries 3 --max-episode-len 125 --num-episodes 60000 --save-dir "./policy-tag_s1_base-60000/" --exp-name tag_s1_base --benchmark

python train.py --scenario tag_s_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s_base_run2-60000/" --exp-name tag_s_base_run2 --benchmark
python train.py --scenario tag_s_base_Wdistance --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s_base_Wdistance_run2-60000/" --exp-name tag_s_base_Wdistance_run2 --benchmark
python train.py --scenario tag_s_comm --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s_comm_run2-60000/" --exp-name tag_s_comm_run2 --benchmark

python train.py --scenario tag_s0_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s0_base-60000/" --exp-name tag_s0_base --benchmark
python train.py --scenario tag_s0_base_Wdistance --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s0_base_Wdistance-60000/" --exp-name tag_s0_base_Wdistance --benchmark
python train.py --scenario tag_s0_comm --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s0_comm-60000/" --exp-name tag_s0_comm --benchmark

python train.py --scenario tag_s0_base --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s0_base_run2-60000/" --exp-name tag_s0_base_run2 --benchmark
python train.py --scenario tag_s0_base_Wdistance --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s0_base_Wdistance_run2-60000/" --exp-name tag_s0_base_Wdistance_run2 --benchmark
python train.py --scenario tag_s0_comm --num-adversaries 3 --num-episodes 60000 --save-dir "./policy-tag_s0_comm_run2-60000/" --exp-name tag_s0_comm_run2 --benchmark

python train.py --scenario tag_s_comm --num-adversaries 3 --num-episodes 30000 --load-dir "./policy-tag_s_comm-60000/" --save-dir "./policy-tag_s_comm-90000/" --exp-name tag_s_comm_9000 --benchmark

python runExperiments.py --scenario tag_s_los_comm --start-iter 1 --end-iter 6 --num-units 64 --initial-exp-name tag_s_los_comm_LONG --initial-dir "./policy-tag_s_los_comm_LONG"


python runExperiments.py --scenario tag_s_base --start-iter 1 --end-iter 12 --num-units-adv 32 --num-units-good 64 --initial-exp-name tag_s_base_32_64_LONG --initial-dir "./policy-tag_s_base_32_64_LONG"
python runExperiments.py --scenario tag_s_base_Wdistance --start-iter 1 --end-iter 12 --num-units-adv 32 --num-units-good 64 --initial-exp-name tag_s_base_Wdistance_32_64_LONG --initial-dir "./policy-tag_s_base_Wdistance_32_64_LONG"
python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 12 --num-units-adv 32 --num-units-good 64 --initial-exp-name tag_s_comm_32_64_LONG --initial-dir "./policy-tag_s_comm_32_64_LONG"

python runExperiments.py --scenario tag_s_base --start-iter 1 --end-iter 6 --initial-exp-name tag_s_base__64_32__LONG --initial-dir "./policy-tag_s_base__64_32__LONG" --benchmark-interval 2
python runExperiments.py --scenario tag_s_base_Wdistance --start-iter 1 --end-iter 6 --initial-exp-name tag_s_base_Wdistance__64_32__LONG --initial-dir "./policy-tag_s_base_Wdistance__64_32__LONG" --benchmark-interval 2
python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --initial-exp-name tag_s_comm__64_32__LONG --initial-dir "./policy-tag_s_comm__64_32__LONG" --benchmark-interval 2


python runExperiments.py --scenario tag_s_base --start-iter 1 --end-iter 6 --num-units-adv 32 --initial-exp-name tag_s_base__32__LONG --initial-dir "./policy-tag_s_base__32__LONG" --benchmark-interval 2
python runExperiments.py --scenario tag_s_base_Wdistance --start-iter 1 --end-iter 6 --num-units-adv 32 --initial-exp-name tag_s_base_Wdistance__32__LONG --initial-dir "./policy-tag_s_base_Wdistance__32__LONG" --benchmark-interval 2
python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --num-units-adv 32 --initial-exp-name tag_s_comm__32__LONG --initial-dir "./policy-tag_s_comm__32__LONG" --benchmark-interval 2

python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --num-units-adv 16 --initial-exp-name tag_s_comm__16__LONG --initial-dir "./policy-tag_s_comm__16__LONG" --benchmark-interval 2
python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --num-units-adv 128 --initial-exp-name tag_s_comm__128__LONG --initial-dir "./policy-tag_s_comm__128__LONG" --benchmark-interval 2


python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --initial-exp-name tag_s_comm__64_64_64__LONG --initial-dir "./policy-tag_s_comm__64_64_64__LONG" --benchmark-interval 2
python runExperiments2.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --initial-exp-name tag_s_comm__64_32_64__LONG --initial-dir "./policy-tag_s_comm__64_32_64__LONG" --benchmark-interval 2
python runExperiments3.py --scenario tag_s_base_Wdistance --start-iter 16 --end-iter 18 --initial-exp-name tag_s_base_Wdistance_LONG --initial-dir "./policy-tag_s_base_Wdistance_LONG" --benchmark-interval 1

python runExperiments3.py --scenario tag_s_comm --start-iter 16 --end-iter 18 --initial-exp-name tag_s_comm_LONG --initial-dir "./policy-tag_s_comm_LONG" --benchmark-interval 1
python runExperiments3.py --scenario tag_s_base --start-iter 16 --end-iter 18 --initial-exp-name tag_s_base_LONG --initial-dir "./policy-tag_s_base_LONG" --benchmark-interval 1


python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --initial-exp-name tag_s_comm__64_32__LONG2 --initial-dir "./policy-tag_s_comm__64_32__LONG2" --benchmark-interval 2
python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --initial-exp-name tag_s_comm__64_32__LONG3 --initial-dir "./policy-tag_s_comm__64_32__LONG3" --benchmark-interval 2


python runExperiments.py --scenario tag_s_comm --start-iter 7 --end-iter 8 --initial-exp-name tag_s_comm__64_32__LONG --initial-dir "./policy-tag_s_comm__64_32__LONG" --benchmark-interval 2 &&
python runExperiments.py --scenario tag_s_comm --start-iter 7 --end-iter 8 --initial-exp-name tag_s_comm__64_32__LONG2 --initial-dir "./policy-tag_s_comm__64_32__LONG2" --benchmark-interval 2 &&
python runExperiments.py --scenario tag_s_comm --start-iter 7 --end-iter 8 --initial-exp-name tag_s_comm__64_32__LONG3 --initial-dir "./policy-tag_s_comm__64_32__LONG3" --benchmark-interval 2 &&
shutdown now


python train3.py --num-adversaries 3 --num-episodes 10000 --scenario tag_s_comm --save-dir ./policy-tag_s_comm_LONG_30000/ --exp-name tag_s_comm_LONG_30000 --display

python runExperiments3.py --scenario tag_s_comm --start-iter 1 --end-iter 20 --num-episodes 2000 --initial-exp-name tag_s_comm_SHORT --initial-dir "./policy-tag_s_comm_SHORT"
python runExperiments3.py --scenario tag_s_comm --start-iter 1 --end-iter 20 --num-episodes 2000 --initial-exp-name tag_s_comm_2SHORT --initial-dir "./policy-tag_s_comm_2SHORT" --benchmark no


python runExperiments.py --scenario tag_s_comm --start-iter 1 --end-iter 6 --initial-exp-name tag_s_comm__64_96_64_32__LONG --initial-dir "./policy-tag_s_comm__64_96_64_32__LONG"

python runExperiments2.py --scenario tag_s_comm --start-iter 7 --end-iter 10 --initial-exp-name tag_s_comm__128_64_32__LONG --initial-dir "./policy-tag_s_comm__128_64_32__LONG" &&
python runExperiments2.py --scenario tag_s_comm --start-iter 1 --end-iter 10 --initial-exp-name tag_s_comm__128_64_32__2LONG --initial-dir "./policy-tag_s_comm__128_64_32__2LONG" &&
shutdown now


python runExperiments3.py --scenario tag_s_base --start-iter 1 --end-iter 20 --num-episodes 2000 --initial-exp-name tag_s_base_SHORT --initial-dir "./policy-tag_s_base_SHORT" x

python runExperiments3.py --scenario tag_s_base_Wdistance --start-iter 1 --end-iter 20 --num-episodes 2000 --initial-exp-name tag_s_base_Wdistance_SHORT --initial-dir "./policy-tag_s_base_Wdistance_SHORT" x

128 - 64 - 32 - 5
64 - 32 - 5
64 - 96 - 64 - 32 - 5

literature on how to design network around useful and unuseful information, (autoencoders)